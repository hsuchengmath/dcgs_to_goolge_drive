{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "rating_data = pd.read_csv('data/rating_BETA_Jan.csv', encoding='utf-8-sig')\n",
    "user_data = pd.read_csv('data/user_feature_BETA_Jan.csv', encoding='utf-8-sig')\n",
    "mat_data = pd.read_csv('data/material_feature_BETA_Jan.csv', encoding='utf-8-sig')\n",
    "review_data = pd.read_csv('data/review_BETA_Jan.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35288/35288 [00:30<00:00, 1160.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# only materialpointsCNT == 1 in rating_data\n",
    "# w/o repeat mat score in rating_data\n",
    "rating_data = rating_data[rating_data['materialpointsCNT'] == 1]\n",
    "uid_list = list(set(rating_data['client_sn']))\n",
    "rating_data_wo_repeat = list()\n",
    "for uid in tqdm(uid_list):\n",
    "    dat = rating_data[rating_data['client_sn'] == uid]\n",
    "    if len(set(dat['material_points'])) > 1:\n",
    "        rating_data_wo_repeat.append(dat)\n",
    "rating_data = pd.concat(rating_data_wo_repeat).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_sn</th>\n",
       "      <th>MaterialID</th>\n",
       "      <th>con_sn</th>\n",
       "      <th>session_sn</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>PurchaseBrandID</th>\n",
       "      <th>attend_level</th>\n",
       "      <th>attend_date</th>\n",
       "      <th>sestime</th>\n",
       "      <th>week</th>\n",
       "      <th>materialpointsCNT</th>\n",
       "      <th>material_points</th>\n",
       "      <th>consultantpointsCNT</th>\n",
       "      <th>consultant_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354714</td>\n",
       "      <td>118145</td>\n",
       "      <td>28851.0</td>\n",
       "      <td>2021010422472454</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_sn  MaterialID   con_sn        session_sn MaterialType  \\\n",
       "0   10354714      118145  28851.0  2021010422472454        Adult   \n",
       "\n",
       "   PurchaseBrandID  attend_level attend_date  sestime  week  \\\n",
       "0                1            11  2021-01-04       22     1   \n",
       "\n",
       "   materialpointsCNT  material_points  consultantpointsCNT  consultant_points  \n",
       "0                  1               10                    1                  9  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17907/17907 [00:37<00:00, 480.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# add label feature to rating_data\n",
    "import numpy as np\n",
    "rating_data['label'] = [np.nan for _ in range(rating_data.shape[0])]\n",
    "uid_list = list(set(rating_data['client_sn']))\n",
    "for uid in tqdm(uid_list):\n",
    "    dat = rating_data[rating_data['client_sn'] == uid]\n",
    "    index = dat.index\n",
    "    score_list = list(dat['material_points'])\n",
    "    max_score = max(score_list)\n",
    "    label_list = []\n",
    "    for score in score_list:\n",
    "        if score == max_score:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "    rating_data.loc[index, 'label']   = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 'client_sn','MaterialID','session_sn','PurchaseBrandID','attend_level','attend_date','label' as feature in rating_data\n",
    "rating_data = rating_data[['client_sn','MaterialID','session_sn','PurchaseBrandID','attend_level','attend_date','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_sn</th>\n",
       "      <th>MaterialID</th>\n",
       "      <th>session_sn</th>\n",
       "      <th>PurchaseBrandID</th>\n",
       "      <th>attend_level</th>\n",
       "      <th>attend_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354714</td>\n",
       "      <td>118145</td>\n",
       "      <td>2021010422472454</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_sn  MaterialID        session_sn  PurchaseBrandID  attend_level  \\\n",
       "0   10354714      118145  2021010422472454                1            11   \n",
       "\n",
       "  attend_date  label  \n",
       "0  2021-01-04    1.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build rating_review_data by merging rating_data, review_data. where key = ['client_sn','MaterialID','session_sn'] (left join)\n",
    "rating_review_data = pd.merge(rating_data, review_data, on=['client_sn','MaterialID','session_sn'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_sn</th>\n",
       "      <th>MaterialID</th>\n",
       "      <th>session_sn</th>\n",
       "      <th>PurchaseBrandID</th>\n",
       "      <th>attend_level</th>\n",
       "      <th>attend_date</th>\n",
       "      <th>label</th>\n",
       "      <th>con_sn</th>\n",
       "      <th>compliment_INT</th>\n",
       "      <th>compliment_PRA</th>\n",
       "      <th>compliment_COR</th>\n",
       "      <th>complaint_DFG</th>\n",
       "      <th>complaint_DFV</th>\n",
       "      <th>complaint_EAG</th>\n",
       "      <th>complaint_EAV</th>\n",
       "      <th>complaint_BOR</th>\n",
       "      <th>complaint_OFA</th>\n",
       "      <th>complaint_ECA</th>\n",
       "      <th>complaint_ECR</th>\n",
       "      <th>complaint_ECV</th>\n",
       "      <th>complaint_ICA</th>\n",
       "      <th>complaint_ICR</th>\n",
       "      <th>complaint_ICV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354714</td>\n",
       "      <td>118145</td>\n",
       "      <td>2021010422472454</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28851.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_sn  MaterialID        session_sn  PurchaseBrandID  attend_level  \\\n",
       "0   10354714      118145  2021010422472454                1            11   \n",
       "\n",
       "  attend_date  label   con_sn  compliment_INT  compliment_PRA  compliment_COR  \\\n",
       "0  2021-01-04    1.0  28851.0             1.0             1.0             1.0   \n",
       "\n",
       "   complaint_DFG  complaint_DFV  complaint_EAG  complaint_EAV  complaint_BOR  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   complaint_OFA  complaint_ECA  complaint_ECR  complaint_ECV  complaint_ICA  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   complaint_ICR  complaint_ICV  \n",
       "0            0.0            0.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_review_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect complain, compliment mat feature\n",
    "mat_individual_col = list(set(rating_review_data.columns)-{'client_sn','MaterialID','session_sn','PurchaseBrandID','attend_level','material_points','con_sn','label','attend_date'})\n",
    "mat_individual_dat = rating_review_data.groupby(['MaterialID']).mean()[mat_individual_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_ECV</th>\n",
       "      <th>complaint_DFG</th>\n",
       "      <th>complaint_EAG</th>\n",
       "      <th>complaint_DFV</th>\n",
       "      <th>complaint_OFA</th>\n",
       "      <th>complaint_ECR</th>\n",
       "      <th>complaint_ICR</th>\n",
       "      <th>complaint_EAV</th>\n",
       "      <th>compliment_PRA</th>\n",
       "      <th>complaint_ECA</th>\n",
       "      <th>complaint_ICV</th>\n",
       "      <th>compliment_INT</th>\n",
       "      <th>compliment_COR</th>\n",
       "      <th>complaint_ICA</th>\n",
       "      <th>complaint_BOR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaterialID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.54878</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.036585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            complaint_ECV  complaint_DFG  complaint_EAG  complaint_DFV  \\\n",
       "MaterialID                                                               \n",
       "100059                0.0            0.0       0.036585       0.012195   \n",
       "\n",
       "            complaint_OFA  complaint_ECR  complaint_ICR  complaint_EAV  \\\n",
       "MaterialID                                                               \n",
       "100059           0.012195        0.02439       0.036585       0.012195   \n",
       "\n",
       "            compliment_PRA  complaint_ECA  complaint_ICV  compliment_INT  \\\n",
       "MaterialID                                                                 \n",
       "100059            0.341463            0.0        0.02439         0.54878   \n",
       "\n",
       "            compliment_COR  complaint_ICA  complaint_BOR  \n",
       "MaterialID                                                \n",
       "100059            0.195122        0.02439       0.036585  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_individual_dat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build rating_matF_data by merging rating_data, mat_individual_dat\n",
    "rating_matF_data = pd.merge(rating_data, mat_individual_dat, on=['MaterialID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sperate adult, jr data by PurchaseBrandID\n",
    "rating_matF_data_AD = rating_matF_data[rating_matF_data['PurchaseBrandID']==1]\n",
    "rating_matF_data_Jr = rating_matF_data[rating_matF_data['PurchaseBrandID']!=1]\n",
    "rating_matF_data_AD = rating_matF_data_AD[list(set(rating_matF_data_AD.columns)-{'session_sn','PurchaseBrandID'})]\n",
    "rating_matF_data_Jr = rating_matF_data_Jr[list(set(rating_matF_data_Jr.columns)-{'session_sn','PurchaseBrandID'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sperate train, test data by attend_date\n",
    "start_date = '2021-01-01'\n",
    "train_date = '2021-04-01'\n",
    "end_date = '2021-05-01'\n",
    "train_data_AD = rating_matF_data_AD[(rating_matF_data_AD['attend_date'] >= start_date) & (rating_matF_data_AD['attend_date'] < train_date)]\n",
    "test_data_AD = rating_matF_data_AD[(rating_matF_data_AD['attend_date'] >= train_date) & (rating_matF_data_AD['attend_date'] < end_date)]\n",
    "train_data_Jr = rating_matF_data_Jr[(rating_matF_data_Jr['attend_date'] >= start_date) & (rating_matF_data_Jr['attend_date'] < train_date)]\n",
    "test_data_Jr = rating_matF_data_Jr[(rating_matF_data_Jr['attend_date'] >= train_date) & (rating_matF_data_Jr['attend_date'] < end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_AD = train_data_AD[list(set(train_data_AD.columns)-{'attend_date'})]\n",
    "test_data_AD = test_data_AD[list(set(test_data_AD.columns)-{'attend_date'})]\n",
    "train_data_Jr = train_data_Jr[list(set(train_data_Jr.columns)-{'attend_date'})]\n",
    "test_data_Jr = test_data_Jr[list(set(test_data_Jr.columns)-{'attend_date'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_AD = np.array(train_data_AD['label'])\n",
    "label_Jr = np.array(train_data_Jr['label'])\n",
    "train_data_AD = train_data_AD[list(set(train_data_AD.columns)-{'label'})]\n",
    "train_data_Jr = train_data_Jr[list(set(train_data_Jr.columns)-{'label'})]\n",
    "ground_truth_AD = np.array(test_data_AD['label'])\n",
    "ground_truth_Jr = np.array(test_data_Jr['label'])\n",
    "test_data_AD = test_data_AD[list(set(test_data_AD.columns)-{'label'})]\n",
    "test_data_Jr = test_data_Jr[list(set(test_data_Jr.columns)-{'label'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def train_model(train_data,label):\n",
    "    train_data = np.array(train_data)\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(train_data, label)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsucheng/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/hsucheng/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_AD = train_model(train_data=train_data_AD, label=label_AD)\n",
    "model_Jr = train_model(train_data=train_data_Jr, label=label_Jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "def predict_score(pred_prob, Y_test_array, binary_threshold=0.5):\n",
    "    pred_one_hot = list()\n",
    "    for i in range(pred_prob.shape[0]):\n",
    "        if pred_prob[i] >= binary_threshold:\n",
    "            pred_one_hot.append(1)\n",
    "        else:\n",
    "            pred_one_hot.append(0)\n",
    "    print(metrics.classification_report(list(Y_test_array), pred_one_hot))\n",
    "    print('---------------------------------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(np.transpose(confusion_matrix(list(Y_test_array), pred_one_hot).T))\n",
    "    print('---------------------------------------')\n",
    "    print('positive label : 1 | negative label : 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.32      0.36     11923\n",
      "         1.0       0.65      0.75      0.70     20223\n",
      "\n",
      "    accuracy                           0.59     32146\n",
      "   macro avg       0.54      0.53      0.53     32146\n",
      "weighted avg       0.57      0.59      0.57     32146\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix\n",
      "[[ 3762  8161]\n",
      " [ 4977 15246]]\n",
      "---------------------------------------\n",
      "positive label : 1 | negative label : 0\n"
     ]
    }
   ],
   "source": [
    "test_data_AD_array = np.array(test_data_AD)\n",
    "y_pred_AD = model_AD.predict(test_data_AD_array)\n",
    "predict_score(y_pred_AD,ground_truth_AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.50      0.43     11923\n",
      "         1.0       0.63      0.50      0.56     20223\n",
      "\n",
      "    accuracy                           0.50     32146\n",
      "   macro avg       0.50      0.50      0.49     32146\n",
      "weighted avg       0.53      0.50      0.51     32146\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix\n",
      "[[ 5960  5963]\n",
      " [10105 10118]]\n",
      "---------------------------------------\n",
      "positive label : 1 | negative label : 0\n"
     ]
    }
   ],
   "source": [
    "ground_truth_AD_list = list(ground_truth_AD)\n",
    "pos,neg = 0,0\n",
    "for val in ground_truth_AD_list:\n",
    "    if int(val) == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "import random\n",
    "random_pred = np.array([random.sample([1,0],1)[0] for _ in range(len(ground_truth_AD))])\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "predict_score(random_pred,ground_truth_AD_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.27      0.31     12373\n",
      "         1.0       0.67      0.76      0.71     23560\n",
      "\n",
      "    accuracy                           0.59     35933\n",
      "   macro avg       0.52      0.52      0.51     35933\n",
      "weighted avg       0.57      0.59      0.57     35933\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix\n",
      "[[ 3337  9036]\n",
      " [ 5570 17990]]\n",
      "---------------------------------------\n",
      "positive label : 1 | negative label : 0\n"
     ]
    }
   ],
   "source": [
    "test_data_Jr_array = np.array(test_data_Jr)\n",
    "y_pred_Jr = model_Jr.predict(test_data_Jr_array)\n",
    "predict_score(y_pred_Jr,ground_truth_Jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.50      0.41     12373\n",
      "         1.0       0.66      0.50      0.57     23560\n",
      "\n",
      "    accuracy                           0.50     35933\n",
      "   macro avg       0.50      0.50      0.49     35933\n",
      "weighted avg       0.55      0.50      0.51     35933\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix\n",
      "[[ 6208  6165]\n",
      " [11709 11851]]\n",
      "---------------------------------------\n",
      "positive label : 1 | negative label : 0\n"
     ]
    }
   ],
   "source": [
    "ground_truth_Jr_list = list(ground_truth_Jr)\n",
    "pos,neg = 0,0\n",
    "for val in ground_truth_Jr_list:\n",
    "    if int(val) == 1:\n",
    "        pos +=1\n",
    "    else:\n",
    "        neg +=1\n",
    "import random\n",
    "random_pred = np.array([random.sample([1,0],1)[0] for _ in range(len(ground_truth_Jr_list))])\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "predict_score(random_pred,ground_truth_Jr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
